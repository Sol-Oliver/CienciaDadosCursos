{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear Multipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as sm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.1</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.460</td>\n",
       "      <td>20.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.3</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.570</td>\n",
       "      <td>15.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.4</td>\n",
       "      <td>4</td>\n",
       "      <td>146.7</td>\n",
       "      <td>62</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.190</td>\n",
       "      <td>20.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>140.8</td>\n",
       "      <td>95</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.150</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19.2</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.8</td>\n",
       "      <td>6</td>\n",
       "      <td>167.6</td>\n",
       "      <td>123</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3.440</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16.4</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>4.070</td>\n",
       "      <td>17.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17.3</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.730</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>275.8</td>\n",
       "      <td>180</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.780</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>472.0</td>\n",
       "      <td>205</td>\n",
       "      <td>2.93</td>\n",
       "      <td>5.250</td>\n",
       "      <td>17.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "      <td>460.0</td>\n",
       "      <td>215</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.424</td>\n",
       "      <td>17.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.7</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>230</td>\n",
       "      <td>3.23</td>\n",
       "      <td>5.345</td>\n",
       "      <td>17.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32.4</td>\n",
       "      <td>4</td>\n",
       "      <td>78.7</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>2.200</td>\n",
       "      <td>19.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>75.7</td>\n",
       "      <td>52</td>\n",
       "      <td>4.93</td>\n",
       "      <td>1.615</td>\n",
       "      <td>18.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33.9</td>\n",
       "      <td>4</td>\n",
       "      <td>71.1</td>\n",
       "      <td>65</td>\n",
       "      <td>4.22</td>\n",
       "      <td>1.835</td>\n",
       "      <td>19.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.5</td>\n",
       "      <td>4</td>\n",
       "      <td>120.1</td>\n",
       "      <td>97</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.465</td>\n",
       "      <td>20.01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15.5</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>2.76</td>\n",
       "      <td>3.520</td>\n",
       "      <td>16.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.2</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.435</td>\n",
       "      <td>17.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.3</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>245</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.840</td>\n",
       "      <td>15.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>19.2</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.845</td>\n",
       "      <td>17.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.3</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>66</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1.935</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.3</td>\n",
       "      <td>91</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.140</td>\n",
       "      <td>16.70</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30.4</td>\n",
       "      <td>4</td>\n",
       "      <td>95.1</td>\n",
       "      <td>113</td>\n",
       "      <td>3.77</td>\n",
       "      <td>1.513</td>\n",
       "      <td>16.90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.8</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>264</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.170</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>19.7</td>\n",
       "      <td>6</td>\n",
       "      <td>145.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.62</td>\n",
       "      <td>2.770</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>301.0</td>\n",
       "      <td>335</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.570</td>\n",
       "      <td>14.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>21.4</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>109</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.780</td>\n",
       "      <td>18.60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n",
       "0   21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n",
       "1   21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n",
       "2   22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n",
       "3   21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n",
       "4   18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2\n",
       "5   18.1    6  225.0  105  2.76  3.460  20.22   1   0     3     1\n",
       "6   14.3    8  360.0  245  3.21  3.570  15.84   0   0     3     4\n",
       "7   24.4    4  146.7   62  3.69  3.190  20.00   1   0     4     2\n",
       "8   22.8    4  140.8   95  3.92  3.150  22.90   1   0     4     2\n",
       "9   19.2    6  167.6  123  3.92  3.440  18.30   1   0     4     4\n",
       "10  17.8    6  167.6  123  3.92  3.440  18.90   1   0     4     4\n",
       "11  16.4    8  275.8  180  3.07  4.070  17.40   0   0     3     3\n",
       "12  17.3    8  275.8  180  3.07  3.730  17.60   0   0     3     3\n",
       "13  15.2    8  275.8  180  3.07  3.780  18.00   0   0     3     3\n",
       "14  10.4    8  472.0  205  2.93  5.250  17.98   0   0     3     4\n",
       "15  10.4    8  460.0  215  3.00  5.424  17.82   0   0     3     4\n",
       "16  14.7    8  440.0  230  3.23  5.345  17.42   0   0     3     4\n",
       "17  32.4    4   78.7   66  4.08  2.200  19.47   1   1     4     1\n",
       "18  30.4    4   75.7   52  4.93  1.615  18.52   1   1     4     2\n",
       "19  33.9    4   71.1   65  4.22  1.835  19.90   1   1     4     1\n",
       "20  21.5    4  120.1   97  3.70  2.465  20.01   1   0     3     1\n",
       "21  15.5    8  318.0  150  2.76  3.520  16.87   0   0     3     2\n",
       "22  15.2    8  304.0  150  3.15  3.435  17.30   0   0     3     2\n",
       "23  13.3    8  350.0  245  3.73  3.840  15.41   0   0     3     4\n",
       "24  19.2    8  400.0  175  3.08  3.845  17.05   0   0     3     2\n",
       "25  27.3    4   79.0   66  4.08  1.935  18.90   1   1     4     1\n",
       "26  26.0    4  120.3   91  4.43  2.140  16.70   0   1     5     2\n",
       "27  30.4    4   95.1  113  3.77  1.513  16.90   1   1     5     2\n",
       "28  15.8    8  351.0  264  4.22  3.170  14.50   0   1     5     4\n",
       "29  19.7    6  145.0  175  3.62  2.770  15.50   0   1     5     6\n",
       "30  15.0    8  301.0  335  3.54  3.570  14.60   0   1     5     8\n",
       "31  21.4    4  121.0  109  4.11  2.780  18.60   1   1     4     2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = pd.read_csv('mt_cars.csv')\n",
    "base = base.drop(['Unnamed: 0'], axis = 1)\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = base.iloc[:, 2].values \n",
    "y = base.iloc[:, 0].values\n",
    "correlacao = np.corrcoef(X, y)\n",
    "X = X.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.59985475616395"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = LinearRegression()\n",
    "modelo.fit(X, y)\n",
    "modelo.intercept_  #interceptação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04121512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.coef_   #coeficiente que indica a inclinação da linha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7183433404897299"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.score(X, y) #indica o quanto a variável independente explica a variável dependente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   76.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 04 Jun 2019</td> <th>  Prob (F-statistic):</th> <td>9.38e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:41:00</td>     <th>  Log-Likelihood:    </th> <td> -82.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   168.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    30</td>      <th>  BIC:               </th> <td>   171.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   29.5999</td> <td>    1.230</td> <td>   24.070</td> <td> 0.000</td> <td>   27.088</td> <td>   32.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disp</th>      <td>   -0.0412</td> <td>    0.005</td> <td>   -8.747</td> <td> 0.000</td> <td>   -0.051</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.368</td> <th>  Durbin-Watson:     </th> <td>   1.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.186</td> <th>  Jarque-Bera (JB):  </th> <td>   3.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.719</td> <th>  Prob(JB):          </th> <td>   0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.532</td> <th>  Cond. No.          </th> <td>    558.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.718\n",
       "Model:                            OLS   Adj. R-squared:                  0.709\n",
       "Method:                 Least Squares   F-statistic:                     76.51\n",
       "Date:                Tue, 04 Jun 2019   Prob (F-statistic):           9.38e-10\n",
       "Time:                        16:41:00   Log-Likelihood:                -82.105\n",
       "No. Observations:                  32   AIC:                             168.2\n",
       "Df Residuals:                      30   BIC:                             171.1\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     29.5999      1.230     24.070      0.000      27.088      32.111\n",
       "disp          -0.0412      0.005     -8.747      0.000      -0.051      -0.032\n",
       "==============================================================================\n",
       "Omnibus:                        3.368   Durbin-Watson:                   1.250\n",
       "Prob(Omnibus):                  0.186   Jarque-Bera (JB):                3.049\n",
       "Skew:                           0.719   Prob(JB):                        0.218\n",
       "Kurtosis:                       2.532   Cond. No.                         558.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modelo ajustado\n",
    "previsoes = modelo.predict(X)\n",
    "modelo_ajustado = sm.ols(formula = 'mpg ~ disp', data = base) #fazer a previsão do disp pelo mpg\n",
    "modelo_treinado = modelo_ajustado.fit()\n",
    "modelo_treinado.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x234f25f9668>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHRNJREFUeJzt3Xt0VOW5BvDnzQUxggEkakSSILq8FBRLpFjt0YooRRHx1trowS7XGil1VdR6xGKB2MajLi/0dFVY4WihEm8VvAC2VfB2sBYbKiZ40HohyVEjYJGIYhGS9/zx7WFmkpnMJfs+z2+tWcx8mcl+uxuf7Hzf3u8WVQUREQVfgdcFEBGRPRjoREQhwUAnIgoJBjoRUUgw0ImIQoKBTkQUEgx0IqKQSBvoItJfRF4XkTdF5C0RqbXGl4jIFhHZaD3GOF8uERGlUpTBe/YAOEtVvxCRYgDrROSP1tduUtUnnCuPiIgylTbQ1VxK+oX1sth65HR56dChQ7WqqiqXjxIR5a0NGzZ8qqpl6d4nmVz6LyKFADYAOBrAb1X1ZhFZAuBUmCP4tQBmq+qeJJ+NAIgAQEVFxdjW1tZs/ncQEeU9EdmgqtXp3pfRoqiqdqrqGABHAhgnIqMA3ALgOACnABgC4OYUn61X1WpVrS4rS/sLhoiIcpTVWS6quhPASwAmqWq7GnsA/A7AOAfqIyKiDGVylkuZiAyynh8I4GwAb4tIuTUmAC4EsMnJQomIqHeZnOVSDmCpNY9eAOBxVV0lIi+ISBkAAbARwAwH6yQiojQyOculCcDJScbPcqQiIiLKie+vFG1obkDVgioU1BagakEVGpobvC6JiMiXMply8UxDcwMiKyPYvXc3AKC1oxWRlREAQM3oGi9LIyLyHV8foc9ZO2d/mEft3rsbc9bO8agiIiL/8nWgt3W0ZTVORJTPfB3oFaUVWY0TEeUzXwd63YQ6lBSXJIyVFJegbkKdRxUREfmXrwO9ZnQN6qfUo7K0EgJBZWkl6qfUc0GUiCiJjJpz2aW6ulobGxtd2x4RURjY2pyLiIj8j4FORBQSDHQiopBgoBMRhQQDnYgoJAIb6GzaRUSUyNfNuVJh0y4iop4CeYTOpl1ERD0FMtDZtIuIqKdABjqbdhER9RTIQGfTLiKingIZ6GzaRUTUE5tzERH5HJtzERHlGQY6EVFIMNCJiEKCgU5EFBIMdCKikGCgExGFBAOdiCgkGOhERCERuEDPtQ86+6cTUdgFqh96rn3Q2T+diPJBoI7Qc+2Dzv7pRJQP0ga6iPQXkddF5E0ReUtEaq3xESKyXkTeFZHHRKSf08Xm2ged/dOJKB9kcoS+B8BZqnoSgDEAJonIeAB3ArhPVY8B8BmAq50r08i1Dzr7pxNRPkgb6Gp8Yb0sth4K4CwAT1jjSwFc6EiFcXLtg87+6USUDzKaQxeRQhHZCGAbgOcBvA9gp6rus97yIYBhzpQYk2sfdPZPJ6J8kFU/dBEZBOBJAHMB/E5Vj7bGhwN4VlVHJ/lMBEAEACoqKsa2trbaUTcRUd5wpB+6qu4E8BKA8QAGiUj0tMcjAXyc4jP1qlqtqtVlZWXZbI6IiLKQyVkuZdaROUTkQABnA9gM4EUAl1hvmw7gaaeKJCKi9DK5sKgcwFIRKYT5BfC4qq4Skf8F8KiI/ArAGwAecLBOIiJKI22gq2oTgJOTjH8AYJwTRRERUfYCdaUoERGlxkAnIgoJBjoRUUgw0ImIQoKBTkQUEgx0IqKQYKATEYUEA52IKCQY6EREIcFAJyIKCQY6EVFIMNCJiEKCgU5EFBIMdCKikAhsoDc0N6BqQRUKagtQtaAKDc0NXpdEROSpTG5w4TsNzQ2IrIxg997dAIDWjlZEVkYAgDd+JqK8Fcgj9Dlr5+wP86jde3djzto5HlVEROS9QAZ6W0dbVuNERPkgkIFeUVqR1TgRUT4IZKDXTahDSXFJwlhJcQnqJtR5VBERkfcCGeg1o2tQP6UelaWVEAgqSytRP6WeC6JElNdEVV3bWHV1tTY2Nmb/wd27gS1bgG98w/6iiIh8TkQ2qGp1uvcF4wi9vh4YNQoQAa6/Hujq8roiIiLfCUagX3UVMHiweb5gAVBYCJxxBrBrl6dlERH5STACfdAgYMcOE+ATJpixV14BDj7YHLU//7y39RER+UAwAj1qwABgzRqgsxO46abY+DnnmGC/5RbXSmHrASLym2AFelRBAXDXXYAqMHlybPyOO0ywjxzp6OajrQdaO1qh0P2tBxjqROSlYAZ6vNWrTbAvXBgb++ADE+wiwFdf2b5Jth4gIj8KfqBHzZhhgv2NNxLHS0pMsL/zjm2bYusBIvKj8AR61JgxJtg7OhLHjzvOBPvDD/d5E2w9QER+FL5Ajzr4YBPsXV3AwIGx8ZoaE+wHH5zzt2brASLyo/AGepQI8PnnJtyvuio2vmtXbJ49y6tl2XqAiPwoGJf+2+1XvwJ+8Yue4x9/DJSXu18PEVEvbLv0X0SGi8iLIrJZRN4Skeus8fki8pGIbLQek9N9L9+49VZzVN79l8sRR5gj9qee8qYuIqI+yOQWdPsA3KiqfxeRgQA2iEj00sz7VPVu58pz2NixJth37wYOOig2Pm2a+XfECHMKJBFRAKQNdFVtB9BuPd8lIpsBDHO6MFeVlMTm0UVi41u2xF67ODVFRJSLrBZFRaQKwMkA1ltD14pIk4g8KCKDU3wmIiKNItK4ffv2PhXrClXzKOr2uy66gLpnjzd1ERGlkXGgi8gAAMsBzFLVzwEsBDASwBiYI/h7kn1OVetVtVpVq8vKymwo2SV795pgr61NHO/f3wT73/7mTV1ERClkFOgiUgwT5g2qugIAVHWrqnaqaheAxQDGOVemh+bONcHe3Jw4Pm6cCfbbbrNlM2z2RUR9lclZLgLgAQCbVfXeuPH48/umAdhkf3k+MmqUCfa9exPH580zwT446YxTRtjsi4jskMkR+mkArgRwVrdTFO8SkWYRaQLwXQDXO1mobxQVxebZ4+3cGZtnzxKbfRGRHTI5y2UdgGQp9az95QRMNNSnTAFWrYqNR0P9s8/MzTnSYLMvIrJD+C/9d8PKlSbcly9PHB882IT7mjW9fpzNvojIDgx0O110kQn2rVsTxydONMH+ox8l/RibfRGRHRjoTjj00Finx3hLliSdZ2ezLyKyQ3425/JCqsXSzk5zSz0iohRsa85FNomeGXPjjYnjhYUm7P/xD2/qIqLQYKC77e67TbD/+c+J48cea4L9xz/2pi4iCjwGulfOOSf5rfIWLcr5fHYiym8MdK9Fb5WXbC2DwU5EWWCg+0m6YP/yS/drIqLAYKD7UTTYL700cXzAABPsq1d7UxcR+RoDvRs3uh5mvI3HHzfB/uqriePnn2+C/bzzbK+NiIIrk1vQ5Y1o18Noo6xo10MAtl3kk9M2vv3tWKfHfv1i488+yzsqEdF+PEKP40bXwz5to7iYC6hElBIDPY4bXQ9t20Y02OOP2IFYsH/ySY4VElFQMdDjuNH10PZt7Nljgv2ebncALC83wb54cW7fl4gCh4Eex42uh45t44YbTLC3tCSORyIm2A8/vG/fn4h8j4Eex42uh45vo7IyeafHrVs5z04Ucuy2mA9Shfi+faY5GBH5GrstUkx0AfXUUxPHi4pM2Dc3e1MXEdmKgZ5P/vIXE+xPPZU4fuKJJthvusmbuojIFgz0HLhxNamjpk5N3unx7rs5z04UYAz0LEWv9GztaIVC0drRiitXXImZq2d6XVr2QtzpMfC/dIlywEDPUrIrPRWKRY2Lgh0aIer0mOyXbmRlJNj//xBlgIGepVRXdCrU1hYBnokG+4wZiePRTo/d77TkQ260cCDyIwZ6lnq7otPOFgGeW7jQBHv300wnTTLBfu653tSVATdaOBD5EQM9S3UT6iBIPrdsZ4uAVGaunomi24ogtYKi24qcn7sfOzbW6THec8/5dp7djRYORH7EQM9SzegazKie0SPU7W4RkMzM1TOxsHEhOrUTANCpnVjYuNCdBdmiosAsoLrRwoHIjxjoObj/vPvx0EUPOdoiIJn6DfVZjTsmGuwliaG5P9jb292tpxs3WjgQ+REv/Q8QqU19FKzzPLzBxa9/Dcya1XN80SLgmmvcr4coZHjpfwgVSvK+K6nGXXPddeaIva3bouOMGeaIfehQb+oiyjMM9ACJjI1kNe664cOTd3r85z99N89OFEa8p2iA3H/e/QDMnHmndqJQChEZG9k/7hsiscXT7iEefc1Oj0S2SzuHLiLDAfwewOEAugDUq+qvRWQIgMcAVAFoAXCZqn7W2/fiHHoeO+MM4JVXeo6/9howfrz79RAFiJ1z6PsA3KiqxwMYD+AnInICgNkA1qrqMQDWWq+Jknv5ZXPUvnJl4vipp5qj9ksv9aYuohBJG+iq2q6qf7ee7wKwGcAwAFMBLLXethTAhU4VSSFy/vkm2D/r9sfcE09wnp2oj7JaFBWRKgAnA1gP4DBVbQdM6AM41O7i8kHedgUcNCgwFyoRBUXGi6IiMgDAcgCzVPVzyfA/OBGJAIgAQEUFL72OF+0KGG0kFe0KCCC/LoJJt4Da0WFa/RJRrzI6QheRYpgwb1DVFdbwVhEpt75eDmBbss+qar2qVqtqdVlZmR01hwa7AnYTPWK/4ILE8dJSE+6PPupNXUQBkTbQxRyKPwBgs6reG/elZwBMt55PB/C0/eWFG7sCpvD00ybY161LHL/8chPslZXe1EXkc5kcoZ8G4EoAZ4nIRusxGcAdACaKyLsAJlqvKQvsCpjGaaeZYP/668TxtjbOsxMlkclZLutUVVT1RFUdYz2eVdV/quoEVT3G+neHGwWHiV1dAUO/sFpczAXUkAv9z7BLeOm/h+zoCph3t1tLF+wtLa6XRH2Tdz/DDmK3xYCrWlCF1o7WHuOVpZVomdXifkFumzsX+OUve47PmwfMn+96OZS9vP8ZzgC7LeaJvF9Yve02c8T+wQeJ47W1nI4JiLz/GbYRAz3guLBqGTGC8+x95NU8Nn+G7cNADzjebi2JdMG+b5/7Nfmcl/PY/Bm2DwM94Hi7tV5Eg33YsMTx4mIT7K+95k1dPuTlRW78GbYPF0UpfzzyCPDDH/YcnzYNWLGi53geKagtgKJnFggEXfO6knyC3MRFUaLuLr/cHLHv3Jk4/uSTeT/PznnscGCgk+s8v4iktJQLqN1wHjscGOjkKt9dRJIu2Ds63K/JA5zHDgfOoYdAQ3MD5qydg7aONlSUVqBuQp1v/0P0/UUkF1+cfD592TKgxp/7lMKPc+h5wndHvGn4/iKS5cvNEXv3M2CuuMIcsR9xhDd1EWWAgR5wQeupHpjFt/HjTbDv3Zs43t6et/Ps5H8M9IDz/RFvN4FbfCsqSj/P7uK0JVFvGOgBF5gjXovfF996PQMnVbAXFJhg795PhshlDPSAC9wRL0yot8xqQde8LrTMavFVmGe0HhEN9traxPGRI02w33qre0UTxeFZLiEQpLNc/CznM3BaW4GqquRf43QM2SDTs1yK3CiGnFUzuoYBboOc1yMqK2PB3X2xNPqawU4u4JQLkcWW9Yh0C6jdz5ohshEDnchi63pENNgnTkwc79fPBPu6dX2olCg5BjqRxZEzcJ57zgT7Y48ljn/nOybYp0zpW9FEcbgoSuSmXbuAgw9O/jXOs1MKvPSfKAeOd4IcOJCdHskxPMuFyBI9Dz3aSiF6HjoAZ84iSndmTEdH6qN5oiR4hE5k8awvTvSI/fvfTxwvLTXh/swzzm6fQoOBTmTxvC/Oo4+aYG9qShyfOtUE++mnu1MHBRYDncjim744o0ebYN+3L3H81Vc5z069YqATWXzXF6ew0JFOj57fApAcw0Ansvi6E2Q02A89NHE82umxLbNpoaDdEIWyw/PQiXwk40Zr9fXANdf0HL/3XuD661N+f9/fApCS4nnoRAGT1dFzJGKO2NvbE8dvuMEcsffvn3Qbni/8kqMY6EQ+kdNpk4cfnnyefc+epAuovln4JUcw0IniOLFgmOn37PPRcwadHn238Eu2ShvoIvKgiGwTkU1xY/NF5CMR2Wg9JjtbJpHznFgwzOZ72nb0HA32yd3+s+zXDzUnXoEnjprtz4Vf6rNMjtCXAJiUZPw+VR1jPZ61tywi99l9pWhDcwOmPzk94+9p+9Hz6tUm2J97LmH4e5fPRcv1rejCPF/dApD6Lm2gq+orAHa4UAuRp+xcMIwemXdqZ8bf07HTJidONMH+5ZeJ4/Pnm6mYAw/s2/cn3+jLHPq1ItJkTckMtq0iIo/YuWCY7Gg/k+/p6A20S0qSz7P/6195ewVq2C6yyjXQFwIYCWAMgHYA96R6o4hERKRRRBq3b9+e4+aInGfnlEdvR/W+WISMBvvw4Ynj0WD/+mtv6nJRGC+yyinQVXWrqnaqaheAxQDG9fLeelWtVtXqsrKyXOskcpydUx6pjsALpdBfi5BtbSbYf/ObxPEDDjDBvmWLN3W5wLPumg7KKdBFpDzu5TQAm1K9lyhI7JrySHW0v3TaUv+Eebxrr0VD0zJ8Z84RieNHHWWC/amnvKnLQWG8yCqT0xYfAfAagGNF5EMRuRrAXSLSLCJNAL4LIPW1xkR5yNd9YZKITj+sK/4YMh+Qed3eMG2aCfaf/MSL8hwRxous2MuFiHrv8dJ4OtDQbV550CBgx45AL6R2v0MVYP6K8uMvXvZyIaKM9Tr9sGyZmWdftiz2hZ07Y50ed+1yqUp7Be2vqEzwCJ2IsuvC+PbbwPHH9/wmGzcCJ53kTIF5jkfoRJSxrE7ZPO645BcqjRljjtgXL3awUuoNA52Icpt+iL9QqaoqNh6JmGC/4ALH66ZEnHIhIvvMng3ceWfP8c5OM+dOOeGUCxG57447zBH7n/6UOF5YaI7at23zpq48wUAnyiOu9S4591wT7B9+mDh+2GEm2F9+2Znt5jkGOlGe8KR3ybBhJtj37k0cP/NME+y//KVz285DDHSiPOFp75KiotgC6plnxsbnzjXBztMdbcFAJ8oTvuld8uKLJtjvuy821tRkgr26Gti3z916QoSBTpQnfNe7ZNYsE+zr18fGNmwAiouBU04BPvvMm7oCjIFOlCd8e4PoceNMsO/eHTt3vbERGDLEnB2zebO39QUIA50oT/i+d8mBBwJPPw10dZnb4wHm+QknmOmYVas8LS8IeGEREfnXihXAxRcnjt1+u7mAKcCdHrPFC4uIKPguushMxzQ1xcZ+/nNz1elllwF79nhXmw8x0InI/0aPNsG+fTtw4olm7A9/APr3B44+GvjkE2/r8wkGOhEFx9ChwJtvmptYT59uxt5/HygvN1MwGzZ4W5/HGOhEFDzFxcCSJeaofcGC2Hh1tQn2hx/2rDQvMdCJKNiuu84E+/PPx8Zqakyw33yz+VqeYKATUTicfbYJ7/feAwYONGN33WUWUCdO7HlDjhBioBNRuIwcCXz+uXmccYYZW7MGGDAAOOQQoKXF0/KcxEAnonAaOBB46SVzc41Zs8zYjh3AiBGhbeHLQCeicCsoMI3AVM1CalS0he/ChV5VZjsGOhHlj+nTTbD/9a+xsZkzTbBHIoHv9MhAJ6L8861vmWD/6CNg+HAztnixOR2yujqwnR4Z6ESUv444AmhrA776CrjwQjO2YYPp9FhQELhOjwx0IqL+/YEnnzTdHWtrzZhqrNPjypXe1pchBjoRUZSIuS2equn0GHXBBeZrt9/u6wuVGOhERMlMm2bCu7k5NjZnjpmKueQSX3Z6ZKATEfVm1CgT7J9+GruZ9fLlZppm5Eigvd3b+uIw0ImIMnHIIcDGjabT41VXmbEPPjALqyL44yO3Jf1YQ3MDqhZUoaC2AFULqtDQ3OBYiQx0IqJsFBej4YazcVBdCX46KTb8vR/OM/PsDbHAbmhuQGRlBK0drVAoWjtaEVkZcSzU096CTkQeBHA+gG2qOsoaGwLgMQBVAFoAXKaqaU/c5C3oiCgMqhZUobWjdf/rCe8Dax7q9qaf/Qwjyh9Hy662Hp+vLK1Ey6yWjLdn5y3olgCY1G1sNoC1qnoMgLXWayKivNDWkRjSa0cCMh84+qeIdXq8+25subENa5YCB+3p/fN2SRvoqvoKgB3dhqcCWGo9XwrgQpvrIiLyrYrSiqTj+0ZU9uj0OGEL8MV/Aod+kf7zfZXrHPphqtoOANa/h9pXEhGRv9VNqENJcUnCWElxCeom1JkXVqfHho2/x29OK8L/VABf9EvyPps5vigqIhERaRSRxu3btzu9OSIix9WMrkH9lHpUllZCIKgsrUT9lHrUjK5JfN9JV2LIwiW48vpKfNUv9fvsknZRFABEpArAqrhF0XcAnKmq7SJSDuAlVT023ffhoigRUfbsXBRN5hkA1i23MR3A0zl+HyIisknaQBeRRwC8BuBYEflQRK4GcAeAiSLyLoCJ1msiIvJQUbo3qOrlKb40weZaiIioD3ilKBFRSDDQiYhCgoFORBQSDHQiopDI6Dx02zYmsh1Aa9o3umsogE+9LiIJ1pUd1pUd1pUdr+uqVNWydG9yNdD9SEQaMzlh322sKzusKzusKzt+ras7TrkQEYUEA52IKCQY6EC91wWkwLqyw7qyw7qy49e6EuT9HDoRUVjwCJ2IKCRCH+gi8qCIbBORTXFjQ0TkeRF51/p3sDUuIvJfIvKeiDSJyDddrmu+iHwkIhutx+S4r91i1fWOiJzrUE3DReRFEdksIm+JyHXWuKf7q5e6vN5f/UXkdRF506qr1hofISLrrf31mIj0s8YPsF6/Z329yuW6lojIlrj9NcYad+3n3tpeoYi8ISKrrNee7q9e6vLF/sqKqob6AeDfAHwTwKa4sbsAzLaezwZwp/V8MoA/AhAA4wGsd7mu+QB+luS9JwB4E8ABAEYAeB9AoQM1lQP4pvV8IIB/WNv2dH/1UpfX+0sADLCeFwNYb+2HxwH8wBpfBODH1vOZABZZz38A4DGH9lequpYAuCTJ+137ube2dwOAh2HusQCv91cvdflif2XzCP0RumZ3T9SpAH6vxl8BDBJzAw+36kplKoBHVXWPqm4B8B6AcQ7U1K6qf7ee7wKwGcAweLy/eqkrFbf2l6pq9E6RxdZDAZwF4AlrvPv+iu7HJwBMEBFxsa5UXPu5F5EjAZwH4L+t1wKP91eyutJwbX9lK/SBnkKqe6IOA/B/ce/7EL0HhxOutf6MezA6teFFXdaftyfDHN35Zn91qwvweH9Zf6ZvBLANwPMwfw3sVNV9Sba9vy7r6x0ADnGjLlWN7q86a3/dJyIHdK8rSc12WwDgPwB0Wa8PgQ/2V5K6orzeX1nJ10BPJdlvfzdPA1oIYCSAMQDaAdxjjbtal4gMALAcwCxV/by3tyYZc7Muz/eXqnaq6hgAR8L8FXB8L9v2rC4RGQXgFgDHATgFwBAAN7tZl4icD2Cbqm6IH+5l217WBXi8v3KRr4G+NfonkvXvNmv8QwDD4953JICP3SpKVbda/yF2AViM2DSBa3WJSDFMaDao6gpr2PP9lawuP+yvKFXdCeAlmDnVQSISvXlM/Lb312V9vRSZT7v1ta5J1tSVquoeAL+D+/vrNAAXiEgLgEdhploWwPv91aMuEVnmg/2VtXwN9FT3RH0GwL9bq9jjAXREpxrc0G0ebhqA6BkwzwD4gbXqPwLAMQBed2D7AuABAJtV9d64L3m6v1LV5YP9VSYig6znBwI4G2Z+/0UAl1hv676/ovvxEgAvqLXK5kJdb8f9UhaYeer4/eX4/4+qeouqHqmqVTCLnC+oag083l8p6rrC6/2VEy9WYt18AHgE5s/xvTC/Wa+GmYdbC+Bd698h1nsFwG9h5kGbAVS7XNdD1nabYH5oyuPeP8eq6x0A33OoptNh/nRsArDRekz2en/1UpfX++tEAG9Y298EYK41fhTML5D3APwBwAHWeH/r9XvW149yua4XrP21CcAyxM6Ece3nPq7GMxE7m8TT/dVLXb7ZX5k+eKUoEVFI5OuUCxFR6DDQiYhCgoFORBQSDHQiopBgoBMRhQQDnYgoJBjoREQhwUAnIgqJ/wcjBu4JknE8tQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y, color = 'green')\n",
    "plt.plot(X, previsoes, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.35683076])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.intercept_ + modelo.coef_ * 200   #previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6. , 160. , 110. ],\n",
       "       [  6. , 160. , 110. ],\n",
       "       [  4. , 108. ,  93. ],\n",
       "       [  6. , 258. , 110. ],\n",
       "       [  8. , 360. , 175. ],\n",
       "       [  6. , 225. , 105. ],\n",
       "       [  8. , 360. , 245. ],\n",
       "       [  4. , 146.7,  62. ],\n",
       "       [  4. , 140.8,  95. ],\n",
       "       [  6. , 167.6, 123. ],\n",
       "       [  6. , 167.6, 123. ],\n",
       "       [  8. , 275.8, 180. ],\n",
       "       [  8. , 275.8, 180. ],\n",
       "       [  8. , 275.8, 180. ],\n",
       "       [  8. , 472. , 205. ],\n",
       "       [  8. , 460. , 215. ],\n",
       "       [  8. , 440. , 230. ],\n",
       "       [  4. ,  78.7,  66. ],\n",
       "       [  4. ,  75.7,  52. ],\n",
       "       [  4. ,  71.1,  65. ],\n",
       "       [  4. , 120.1,  97. ],\n",
       "       [  8. , 318. , 150. ],\n",
       "       [  8. , 304. , 150. ],\n",
       "       [  8. , 350. , 245. ],\n",
       "       [  8. , 400. , 175. ],\n",
       "       [  4. ,  79. ,  66. ],\n",
       "       [  4. , 120.3,  91. ],\n",
       "       [  4. ,  95.1, 113. ],\n",
       "       [  8. , 351. , 264. ],\n",
       "       [  6. , 145. , 175. ],\n",
       "       [  8. , 301. , 335. ],\n",
       "       [  4. , 121. , 109. ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#previsão da regressão variavel multipla\n",
    "X1 = base.iloc[:, 1:4].values\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21. , 21. , 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,\n",
       "       16.4, 17.3, 15.2, 10.4, 10.4, 14.7, 32.4, 30.4, 33.9, 21.5, 15.5,\n",
       "       15.2, 13.3, 19.2, 27.3, 26. , 30.4, 15.8, 19.7, 15. , 21.4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = base.iloc[:, 0].values\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2 = LinearRegression()\n",
    "modelo2.fit(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   30.88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 04 Jun 2019</td> <th>  Prob (F-statistic):</th> <td>5.05e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:41:32</td>     <th>  Log-Likelihood:    </th> <td> -79.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   166.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   171.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   34.1849</td> <td>    2.591</td> <td>   13.195</td> <td> 0.000</td> <td>   28.878</td> <td>   39.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cyl</th>       <td>   -1.2274</td> <td>    0.797</td> <td>   -1.540</td> <td> 0.135</td> <td>   -2.861</td> <td>    0.406</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disp</th>      <td>   -0.0188</td> <td>    0.010</td> <td>   -1.811</td> <td> 0.081</td> <td>   -0.040</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hp</th>        <td>   -0.0147</td> <td>    0.015</td> <td>   -1.002</td> <td> 0.325</td> <td>   -0.045</td> <td>    0.015</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.942</td> <th>  Durbin-Watson:     </th> <td>   1.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.230</td> <th>  Jarque-Bera (JB):  </th> <td>   2.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.675</td> <th>  Prob(JB):          </th> <td>   0.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.692</td> <th>  Cond. No.          </th> <td>1.51e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.768\n",
       "Model:                            OLS   Adj. R-squared:                  0.743\n",
       "Method:                 Least Squares   F-statistic:                     30.88\n",
       "Date:                Tue, 04 Jun 2019   Prob (F-statistic):           5.05e-09\n",
       "Time:                        16:41:32   Log-Likelihood:                -79.009\n",
       "No. Observations:                  32   AIC:                             166.0\n",
       "Df Residuals:                      28   BIC:                             171.9\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     34.1849      2.591     13.195      0.000      28.878      39.492\n",
       "cyl           -1.2274      0.797     -1.540      0.135      -2.861       0.406\n",
       "disp          -0.0188      0.010     -1.811      0.081      -0.040       0.002\n",
       "hp            -0.0147      0.015     -1.002      0.325      -0.045       0.015\n",
       "==============================================================================\n",
       "Omnibus:                        2.942   Durbin-Watson:                   1.606\n",
       "Prob(Omnibus):                  0.230   Jarque-Bera (JB):                2.558\n",
       "Skew:                           0.675   Prob(JB):                        0.278\n",
       "Kurtosis:                       2.692   Cond. No.                     1.51e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2.score(X1, y1)\n",
    "modelo_ajustado2 = sm.ols(formula = 'mpg ~ cyl + disp + hp', data = base)\n",
    "modelo_treinado2 = modelo_ajustado2.fit()\n",
    "modelo_treinado2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.03968887])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novo = np.array([4, 200, 100])\n",
    "novo = novo.reshape(1, -1)\n",
    "modelo2.predict(novo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
